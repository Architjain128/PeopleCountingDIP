{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, collections\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "import sys, os\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# People Counting System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change the video number to see the results on any video present in images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes position(i,j), visited matrix, motion vector matrix and threshold on vector magnitude\n",
    "def bfs(i, j, vis, mag, t, region):\n",
    "    util = [-1, 0, 1]\n",
    "    if mag[i][j] < t or vis[i][j] == True:\n",
    "        return 0\n",
    "    q = collections.deque()\n",
    "    area = 0\n",
    "    vis[i][j] = True\n",
    "    q.append([i,j])\n",
    "    while len(q) > 0:\n",
    "        curX, curY = q.popleft()\n",
    "        region[curX][curY] = 255\n",
    "        area += 1\n",
    "        for a in range(3):\n",
    "            for b in range(3):\n",
    "                x = curX + util[a]\n",
    "                y = curY + util[b]\n",
    "                if x >= 0 and y >= 0 and x < mag.shape[0] and y < mag.shape[1] and vis[x][y] != True:\n",
    "                    vis[x][y] = True  \n",
    "                    if mag[x][y] >= t:\n",
    "                        q.append([x, y])\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to color different segmented objects\n",
    "def color_it(img1,c):\n",
    "    img=np.zeros((img1.shape[0],img1.shape[1]))\n",
    "    for i in range(img1.shape[0]):\n",
    "        for j in range(img1.shape[1]):\n",
    "            if img1[i][j] in c:\n",
    "                img[i][j]=255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to count the area of components\n",
    "def dfs(i,j,img,re,vis,c):\n",
    "    if(i<0 or i>=img.shape[0] or j<0 or j>=img.shape[1] or vis[i][j]==1 or img[i][j]==0):\n",
    "        return 0\n",
    "    else:\n",
    "        vis[i][j] = 1\n",
    "        re[i][j] = c\n",
    "        val = 1\n",
    "        if img[i][j] != 0:\n",
    "            val += dfs(i+1,j,img,re,vis,c)\n",
    "            val += dfs(i-1,j,img,re,vis,c)\n",
    "            val += dfs(i,j+1,img,re,vis,c)\n",
    "            val += dfs(i,j-1,img,re,vis,c)\n",
    "            val += dfs(i+1,j+1,img,re,vis,c)\n",
    "            val += dfs(i-1,j-1,img,re,vis,c)\n",
    "            val += dfs(i-1,j+1,img,re,vis,c)\n",
    "            val += dfs(i+1,j-1,img,re,vis,c)\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving object class for each moving object identified\n",
    "# Stores flags to check the position of the object and the centroid\n",
    "class movObj():\n",
    "    def __init__(self, x, y):\n",
    "        self.cx = x\n",
    "        self.cy = y\n",
    "        self.lin1 = False\n",
    "        self.lin2 = False\n",
    "        self.lout1 = False\n",
    "        self.lout2 = False\n",
    "        self.lastUpdate = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the area\n",
    "def count_obj(img,co=255):\n",
    "    count = 1\n",
    "    area = []\n",
    "    re = np.zeros((img.shape[0],img.shape[1]))\n",
    "    visit = np.zeros((img.shape[0],img.shape[1]))\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if visit[i][j]==0 and img[i][j]==co:\n",
    "                temp=[]\n",
    "                temp.append(dfs(i,j,img,re,visit,count))\n",
    "                temp.append(count-1)\n",
    "                area.append(temp)\n",
    "                count += 1\n",
    "    return area,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating centroid of image \n",
    "def centroid_bfs(img,r,c,col,vis):\n",
    "    h,w = img.shape\n",
    "    q = Queue()\n",
    "    q.put((r,c))\n",
    "    vis[r,c] = 1\n",
    "    cent_x = 0\n",
    "    cent_y = 0\n",
    "    cnt = 0\n",
    "    min_x = h+1\n",
    "    min_y = w+1\n",
    "    max_x = 0\n",
    "    max_y = 0\n",
    "    while not q.empty():\n",
    "        r, c = q.get()\n",
    "        min_x = min(min_x,r)\n",
    "        min_y = min(min_y,c)\n",
    "        max_x = max(max_x,r)\n",
    "        max_y = max(max_y,c)\n",
    "        cnt += 1\n",
    "        cent_x += r\n",
    "        cent_y += c\n",
    "        if r-1>=0 and vis[r-1,c] == 0 and img[r-1,c]!=0:\n",
    "            vis[r-1,c] = col\n",
    "            q.put((r-1,c))\n",
    "        if r+1<h and vis[r+1,c] == 0 and img[r+1,c]!=0:\n",
    "            vis[r+1,c] = 1\n",
    "            q.put((r+1,c))\n",
    "        if c-1>=0 and vis[r,c-1] == 0 and img[r,c-1]!=0:\n",
    "            vis[r,c-1] = 1\n",
    "            q.put((r,c-1))\n",
    "        if c+1<w and vis[r,c+1] == 0 and img[r,c+1]!=0:\n",
    "            vis[r,c+1] = 1\n",
    "            q.put((r,c+1))\n",
    "            \n",
    "    cent_x = cent_x//cnt\n",
    "    cent_y = cent_y//cnt\n",
    "    \n",
    "    # bounding box co-ordinates are pushed in an array\n",
    "    arr = [(min_x,min_y),(min_x,max_y),(max_x,min_y),(max_x,max_y)]\n",
    "    \n",
    "    return cent_x, cent_y, arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [(67, 159, [(0, 104), (0, 205), (142, 104), (142, 205)])] 0\n",
      "1 [(63, 166, [(0, 108), (0, 213), (159, 108), (159, 213)])] 1\n",
      "10 149 118 203 67 159 63 166\n",
      "False False False False\n",
      "1 [(79, 155, [(0, 92), (0, 211), (184, 92), (184, 211)])] 1\n",
      "10 174 102 201 63 166 79 155\n",
      "False False False False\n",
      "1 [(83, 160, [(0, 103), (0, 214), (185, 103), (185, 214)])] 1\n",
      "10 175 113 204 79 155 83 160\n",
      "False False False False\n",
      "1 [(93, 150, [(19, 85), (19, 228), (166, 85), (166, 228)])] 1\n",
      "29 156 95 218 83 160 93 150\n",
      "True False False False\n",
      "1 [(103, 157, [(33, 96), (33, 227), (164, 96), (164, 227)])] 1\n",
      "43 154 106 217 93 150 103 157\n",
      "True False False False\n",
      "1 [(106, 172, [(59, 114), (59, 225), (160, 114), (160, 225)])] 1\n",
      "69 150 124 215 103 157 106 172\n",
      "True False False False\n",
      "1 [(114, 157, [(65, 66), (65, 240), (176, 66), (176, 240)])] 1\n",
      "75 166 76 230 106 172 114 157\n",
      "True False False False\n",
      "1 [(146, 178, [(99, 88), (99, 245), (220, 88), (220, 245)])] 1\n",
      "109 210 98 235 114 157 146 178\n",
      "True False False False\n",
      "1 [(153, 174, [(91, 90), (91, 248), (224, 90), (224, 248)])] 1\n",
      "101 214 100 238 146 178 153 174\n",
      "True False False False\n",
      "1 [(137, 157, [(78, 81), (78, 231), (195, 81), (195, 231)])] 1\n",
      "88 185 91 221 153 174 137 157\n",
      "True False False False\n",
      "1 [(132, 146, [(70, 87), (70, 208), (188, 87), (188, 208)])] 1\n",
      "80 178 97 198 137 157 132 146\n",
      "True False False False\n",
      "1 [(83, 120, [(47, 86), (47, 161), (122, 86), (122, 161)])] 1\n",
      "1 [(148, 151, [(103, 98), (103, 215), (193, 98), (193, 215)])] 2\n",
      "113 183 108 205 132 146 148 151\n",
      "True False False False\n",
      "1 [(169, 128, [(143, 87), (143, 174), (201, 87), (201, 174)])] 2\n",
      "0 [] 3\n",
      "0 [] 2\n",
      "1 [(129, 110, [(99, 65), (99, 149), (167, 65), (167, 149)])] 1\n",
      "1 [(156, 141, [(108, 85), (108, 200), (200, 85), (200, 200)])] 1\n",
      "118 190 95 190 129 110 156 141\n",
      "True False False False\n",
      "1 [(149, 131, [(105, 62), (105, 188), (207, 62), (207, 188)])] 1\n",
      "115 197 72 178 156 141 149 131\n",
      "True False False False\n",
      "1 [(164, 138, [(124, 95), (124, 183), (209, 95), (209, 183)])] 1\n",
      "134 199 105 173 149 131 164 138\n",
      "True True False False\n",
      "1 [(142, 87, [(109, 32), (109, 136), (182, 32), (182, 136)])] 1\n",
      "1 [(156, 92, [(114, 42), (114, 141), (193, 42), (193, 141)])] 2\n",
      "124 183 52 131 142 87 156 92\n",
      "True False False False\n",
      "1 [(49, 202, [(0, 148), (0, 281), (123, 148), (123, 281)])] 2\n",
      "1 [(62, 182, [(0, 144), (0, 226), (135, 144), (135, 226)])] 1\n",
      "10 125 154 216 49 202 62 182\n",
      "False False False False\n",
      "1 [(69, 179, [(0, 138), (0, 226), (147, 138), (147, 226)])] 1\n",
      "10 137 148 216 62 182 69 179\n",
      "False False False False\n",
      "1 [(83, 171, [(17, 133), (17, 217), (158, 133), (158, 217)])] 1\n",
      "27 148 143 207 69 179 83 171\n",
      "False False False False\n",
      "1 [(94, 163, [(29, 126), (29, 209), (168, 126), (168, 209)])] 1\n",
      "39 158 136 199 83 171 94 163\n",
      "True False False False\n",
      "1 [(98, 164, [(42, 121), (42, 208), (160, 121), (160, 208)])] 1\n",
      "52 150 131 198 94 163 98 164\n",
      "True False False False\n",
      "1 [(107, 161, [(50, 115), (50, 209), (167, 115), (167, 209)])] 1\n",
      "60 157 125 199 98 164 107 161\n",
      "True False False False\n",
      "1 [(118, 150, [(74, 82), (74, 209), (169, 82), (169, 209)])] 1\n",
      "84 159 92 199 107 161 118 150\n",
      "True False False False\n",
      "1 [(115, 144, [(72, 70), (72, 212), (165, 70), (165, 212)])] 1\n",
      "82 155 80 202 118 150 115 144\n",
      "True False False False\n",
      "1 [(127, 140, [(69, 70), (69, 208), (186, 70), (186, 208)])] 1\n",
      "79 176 80 198 115 144 127 140\n",
      "True False False False\n",
      "1 [(117, 147, [(69, 96), (69, 200), (172, 96), (172, 200)])] 1\n",
      "79 162 106 190 127 140 117 147\n",
      "True False False False\n",
      "1 [(130, 149, [(73, 97), (73, 199), (193, 97), (193, 199)])] 1\n",
      "83 183 107 189 117 147 130 149\n",
      "True False False False\n",
      "1 [(139, 148, [(73, 94), (73, 199), (215, 94), (215, 199)])] 1\n",
      "83 205 104 189 130 149 139 148\n",
      "True False False False\n",
      "1 [(143, 146, [(82, 97), (82, 193), (201, 97), (201, 193)])] 1\n",
      "92 191 107 183 139 148 143 146\n",
      "True False False False\n",
      "1 [(144, 129, [(84, 73), (84, 187), (210, 73), (210, 187)])] 1\n",
      "94 200 83 177 143 146 144 129\n",
      "True False False False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/41/qb6dj_h135v9_gsdxmcjbmhc0000gn/T/ipykernel_58310/3407806693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m                                 \u001b[0msum_Ix\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mIxx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                                 \u001b[0msum_Iy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mIyy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                                 \u001b[0msum_Ixy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mIxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                                 \u001b[0msum_Ix\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# list of persons identified by algorithm\n",
    "listOfObjects = []\n",
    "\n",
    "# variables used for counting\n",
    "in_person = 0\n",
    "out_person = 0\n",
    "\n",
    "# video obj for converting video to frames after 0.1 seconds\n",
    "vidObj = cv2.VideoCapture(\"../input_videos/video\" + str(video_number) + \".avi\")\n",
    "count = 0\n",
    "success = 1\n",
    "sec = 0\n",
    "\n",
    "# Baselines that act as thresholds while counting people\n",
    "someLineOne = 90\n",
    "someLineTwo = 160\n",
    "\n",
    "if not os.path.exists('../output_results'):\n",
    "    os.makedirs('../output_results')\n",
    "\n",
    "if os.path.exists('../output_results/result' + str(video_number) + \".txt\"):\n",
    "    os.remove('../output_results/result' + str(video_number) + \".txt\")\n",
    "\n",
    "while success:\n",
    "    vidObj.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    success, image = vidObj.read()\n",
    "    # if successfully got the frame\n",
    "    if success == 1:\n",
    "        if count == 0:\n",
    "            first_frame = image \n",
    "            prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            frame = image\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # motion estimation\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 1, 5, 2, 5, 1.1, None)\n",
    "            mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "            prev_gray = gray.copy()\n",
    "\n",
    "            # considering only vertical motion \n",
    "            vertical = mag.copy()\n",
    "            for i in range(mag.shape[0]):\n",
    "                for j in range(mag.shape[1]):\n",
    "                    vertical[i][j] = mag[i][j] * abs(np.sin(ang[i][j]))\n",
    "\n",
    "            # calculating varying T (threshold for motion to be considered)\n",
    "            ind = 0\n",
    "            temp_array = [0]*(vertical.shape[0]*vertical.shape[1])\n",
    "            for i in range(vertical.shape[0]):\n",
    "                for j in range(vertical.shape[1]):\n",
    "                    temp_array[ind] = vertical[i][j]\n",
    "                    ind += 1\n",
    "            temp_array = np.array(temp_array)\n",
    "            temp_array = np.sort(temp_array)[::-1]\n",
    "\n",
    "            # top 5% motion values \n",
    "            percent = (5*mag.shape[0]*mag.shape[1])/100\n",
    "            percent = int(percent)\n",
    "            T = temp_array[percent-1]\n",
    "            # if T is less than 2 we assumed that there is no considerate motion in that frame and we can neglect that frame\n",
    "            if T < 2:\n",
    "                count += 1\n",
    "                sec += 0.1\n",
    "                continue\n",
    "\n",
    "            # Calculating feature value M (differential matrix)\n",
    "            dy, dx = np.gradient(gray)\n",
    "            Ixx = dx**2\n",
    "            Iyy = dy**2\n",
    "            Ixy = dx*dy\n",
    "            # R_score is the corner response value considering neighbourhood of 3x3\n",
    "            R_score = np.array(gray.copy(),dtype=np.float64)\n",
    "            for i in range(gray.shape[0]):\n",
    "                for j in range(gray.shape[1]):\n",
    "                    sum_Ix = 0\n",
    "                    sum_Iy = 0\n",
    "                    sum_Ixy = 0\n",
    "                    for k in range(-2,3):\n",
    "                        for l in range(-2,3):\n",
    "                            if i+k >= 0 and j+l >= 0 and i+k < gray.shape[0] and j+l < gray.shape[1]:\n",
    "                                sum_Ix += Ixx[i+k][j+l]\n",
    "                                sum_Iy += Iyy[i+k][j+l]\n",
    "                                sum_Ixy += Ixy[i+k][j+l]\n",
    "                            else:\n",
    "                                sum_Ix += 0\n",
    "                                sum_Iy += 0\n",
    "                                sum_Ixy += 0\n",
    "                    # determinant of Matrix M\n",
    "                    det = sum_Ix*sum_Iy - sum_Ixy*sum_Ixy\n",
    "                    # trace of matrix M\n",
    "                    trace = sum_Ixy + sum_Ixy\n",
    "                    r = det - 0.05*(trace**2)\n",
    "                    R_score[i][j] = r \n",
    "            # converting R_score to 0-255\n",
    "            min_val = np.min(R_score)\n",
    "            R_score += (-1)*min_val\n",
    "            max_val = np.max(R_score)\n",
    "            R_score = (R_score/max_val)*255\n",
    "            R_score = R_score.astype(int)\n",
    "            \n",
    "            # choosing top_features needed to be considered\n",
    "            listOfFeatures = []\n",
    "            listTemp = []\n",
    "            for x in range(frame.shape[0]):\n",
    "                for y in range(frame.shape[1]):\n",
    "                    listTemp.append([R_score[x][y], x, y])\n",
    "            listTemp.sort()\n",
    "            listTemp.reverse()\n",
    "            # considering top total pixel/10 features for feature selection\n",
    "            K = len(listTemp)//10\n",
    "            for x in range(K):\n",
    "                listOfFeatures.append(listTemp[x])\n",
    "            \n",
    "            # region growing\n",
    "            region = np.zeros((frame.shape[0], frame.shape[1]), dtype=int)\n",
    "            vis = [[False for x in range(frame.shape[1])] for y in range(frame.shape[0])]\n",
    "            for point in listOfFeatures:\n",
    "                if vis[point[1]][point[2]] == False:\n",
    "                    area = bfs(point[1], point[2], vis, vertical, T, region)\n",
    "\n",
    "            # component labelling\n",
    "            img_gray = region.copy()\n",
    "\n",
    "            # removing small dots using thresholding \n",
    "            area,re = count_obj(img_gray,255)\n",
    "            thresh1 = 50\n",
    "            ids=[]\n",
    "            for i in area:\n",
    "                if i[0] > thresh1:\n",
    "                    ids.append(i[1]+1)\n",
    "            imgc = color_it(re,ids)\n",
    "            imgc[imgc>0] = 255\n",
    "            thresh2 = 5000\n",
    "\n",
    "            # dilating using rectangular structuring element of 7x7 five times. \n",
    "            img_d=cv2.dilate(imgc,cv2.getStructuringElement(cv2.MORPH_RECT,(7,7)),iterations=5)\n",
    "\n",
    "            # removing components that are not big enough to consider for counting\n",
    "            area,re=count_obj(img_d,255)\n",
    "            ids=[]\n",
    "            for i in area:\n",
    "                if i[0] > thresh2:\n",
    "                    ids.append(i[1]+1)\n",
    "            imgc = color_it(re,ids)\n",
    "            imgc[imgc>0] = 255\n",
    "            thresh3 = 5000\n",
    "            img_d=cv2.dilate(imgc,cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(9,9)),iterations=2)\n",
    "            img_d=cv2.erode(img_d,cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(9,9)),iterations=3)\n",
    "            \n",
    "            # calculating centroid\n",
    "            imgc = img_d.copy()\n",
    "            centroid = []\n",
    "            vis = np.zeros(imgc.shape)\n",
    "            h, w= imgc.shape\n",
    "            for i in range(h):\n",
    "                for j in range(w):\n",
    "                    if imgc[i,j] == 255 and vis[i,j] == 0:\n",
    "                        # the cent_x and cent_y has x,y coordinate of centroid and the array arr has\n",
    "                        # the bounding box coordinate                \n",
    "                        cent_x, cent_y, arr = centroid_bfs(imgc,i,j,1,vis)\n",
    "                        centroid.append((cent_x,cent_y,arr))\n",
    "            \n",
    "            \n",
    "            # counting algorithm based on bounding boxes and centroids to link the currently identified objects\n",
    "            # with the ones identified in the previous frames\n",
    "            for j in range(len(centroid)):\n",
    "                once = False\n",
    "\n",
    "                # x1, x2, y1, y2 form the bounding box\n",
    "                x1, y1 = centroid[j][2][0]\n",
    "                x1 += 10\n",
    "                y1 += 10\n",
    "                x2, y2 = centroid[j][2][3]\n",
    "                x2 -= 10\n",
    "                y2 -= 10 \n",
    "                for obj in listOfObjects:\n",
    "                    # checking if previously identified objects lie within above bounding box\n",
    "                    if obj.cx > x1 and obj.cx < x2 and obj.cy > y1 and obj.cy < y2 and once != True:\n",
    "                        once = True\n",
    "                        prevX = obj.cx\n",
    "                        prevY = obj.cy\n",
    "\n",
    "                        # update centroid of the object\n",
    "                        obj.cx = centroid[j][0]\n",
    "                        obj.cy = centroid[j][1]\n",
    "                        obj.lastUpdate = count\n",
    "\n",
    "                        # below set of conditions check whether the object crosses first line or second line\n",
    "                        # alongwith their direction\n",
    "                        if obj.lin1 == True and obj.cx > someLineTwo and obj.lin2 == False:\n",
    "                            in_person += 1\n",
    "                            obj.lin2 = True\n",
    "                        elif obj.lout2 == True and obj.cx < someLineOne and obj.lout1 == False:\n",
    "                            out_person += 1\n",
    "                            obj.lout1 = True\n",
    "                        elif obj.lin1 == False and obj.cx > someLineOne and prevX < someLineTwo and obj.lin2 == False:\n",
    "                            obj.lin1 = True\n",
    "                        elif obj.lout2 == False and prevX > someLineTwo and obj.cx < someLineTwo and obj.lout1 == False:\n",
    "                            obj.lout2 = True\n",
    "                        break\n",
    "                if once == False:\n",
    "                    # if the identified object is identified for the first time, then create a new object of movObj class\n",
    "                    obj = movObj(centroid[j][0], centroid[j][1])\n",
    "                    listOfObjects.append(obj)\n",
    "                    obj.lastUpdate = count\n",
    "            \n",
    "            tempList = []\n",
    "            # remove objects that seem to have moved out of the frame\n",
    "            for obj in listOfObjects:\n",
    "                if obj.lastUpdate + 2  >= count:\n",
    "                    tempList.append(obj)\n",
    "            listOfObjects = tempList.copy()\n",
    "\n",
    "            # printing the final count for the current frame\n",
    "            with open(\"../output_results/result\" + str(video_number) + \".txt\", 'a') as file:\n",
    "                file.write(\"Time = \" + str(round(count*0.1, 1)) + \"  in-person count - \" + str(in_person) + \"    out-person count - \" + str(out_person))\n",
    "                file.write('\\n')\n",
    "    count += 1\n",
    "    sec += 0.1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "# import seaborn as sns\n",
    "from queue import Queue\n",
    "import sys\n",
    "import random\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidObj = cv2.VideoCapture(\"../images/1/video.avi\")\n",
    "count = 0\n",
    "success = 1\n",
    "sec = 0\n",
    "while success:\n",
    "    vidObj.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    success, image = vidObj.read()\n",
    "    if success == 1:\n",
    "        cv2.imwrite(\"../images/1/frames/frame%d.jpg\" % count, image)\n",
    "    count += 1\n",
    "    sec += 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes position(i,j), visited matrix, motion vector matrix and threshold on vector magnitude\n",
    "def bfs(i, j, vis, mag, t, region):\n",
    "#     print(i,j)\n",
    "    util = [-1, 0, 1]\n",
    "    if mag[i][j] < t or vis[i][j] == True:\n",
    "        return 0\n",
    "    q = collections.deque()\n",
    "    area = 0\n",
    "    vis[i][j] = True\n",
    "    q.append([i,j])\n",
    "    while len(q) > 0:\n",
    "        curX, curY = q.popleft()\n",
    "        region[curX][curY] = 255\n",
    "        area += 1\n",
    "        for a in range(3):\n",
    "            for b in range(3):\n",
    "                x = curX + util[a]\n",
    "                y = curY + util[b]\n",
    "                if x >= 0 and y >= 0 and x < mag.shape[0] and y < mag.shape[1] and vis[x][y] != True:\n",
    "                    vis[x][y] = True  \n",
    "                    if mag[x][y] >= t:\n",
    "                        q.append([x, y])\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to color different segmented objects\n",
    "def color_it(img1,c):\n",
    "    img=np.zeros((img1.shape[0],img1.shape[1]))\n",
    "    for i in range(img1.shape[0]):\n",
    "        for j in range(img1.shape[1]):\n",
    "            if img1[i][j] in c:\n",
    "                img[i][j]=255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to count the area of components\n",
    "def dfs(i,j,img,re,vis,c):\n",
    "    if(i<0 or i>=img.shape[0] or j<0 or j>=img.shape[1] or vis[i][j]==1 or img[i][j]==0):\n",
    "        return 0\n",
    "    else:\n",
    "        vis[i][j] = 1\n",
    "        re[i][j] = c\n",
    "        val = 1\n",
    "        if img[i][j] != 0:\n",
    "            val += dfs(i+1,j,img,re,vis,c)\n",
    "            val += dfs(i-1,j,img,re,vis,c)\n",
    "            val += dfs(i,j+1,img,re,vis,c)\n",
    "            val += dfs(i,j-1,img,re,vis,c)\n",
    "            val += dfs(i+1,j+1,img,re,vis,c)\n",
    "            val += dfs(i-1,j-1,img,re,vis,c)\n",
    "            val += dfs(i-1,j+1,img,re,vis,c)\n",
    "            val += dfs(i+1,j-1,img,re,vis,c)\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the area\n",
    "def count_obj(img,co=255):\n",
    "    count = 1\n",
    "    area = []\n",
    "    re = np.zeros((img.shape[0],img.shape[1]))\n",
    "    visit = np.zeros((img.shape[0],img.shape[1]))\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if visit[i][j]==0 and img[i][j]==co:\n",
    "                temp=[]\n",
    "                temp.append(dfs(i,j,img,re,visit,count))\n",
    "                temp.append(count-1)\n",
    "                area.append(temp)\n",
    "                count += 1\n",
    "    return area,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating centroid of image \n",
    "def centroid_bfs(img,r,c,col,vis):\n",
    "    h,w = img.shape\n",
    "    q = Queue()\n",
    "    q.put((r,c))\n",
    "    vis[r,c] = 1\n",
    "    cent_x = 0\n",
    "    cent_y = 0\n",
    "    cnt = 0\n",
    "    min_x = h+1\n",
    "    min_y = w+1\n",
    "    max_x = 0\n",
    "    max_y = 0\n",
    "    while not q.empty():\n",
    "        r, c = q.get()\n",
    "        min_x = min(min_x,r)\n",
    "        min_y = min(min_y,c)\n",
    "        max_x = max(max_x,r)\n",
    "        max_y = max(max_y,c)\n",
    "        cnt += 1\n",
    "        cent_x += r\n",
    "        cent_y += c\n",
    "        if r-1>=0 and vis[r-1,c] == 0 and img[r-1,c]!=0:\n",
    "            vis[r-1,c] = col\n",
    "            q.put((r-1,c))\n",
    "        if r+1<h and vis[r+1,c] == 0 and img[r+1,c]!=0:\n",
    "            vis[r+1,c] = 1\n",
    "            q.put((r+1,c))\n",
    "        if c-1>=0 and vis[r,c-1] == 0 and img[r,c-1]!=0:\n",
    "            vis[r,c-1] = 1\n",
    "            q.put((r,c-1))\n",
    "        if c+1<w and vis[r,c+1] == 0 and img[r,c+1]!=0:\n",
    "            vis[r,c+1] = 1\n",
    "            q.put((r,c+1))\n",
    "            \n",
    "    cent_x = cent_x//cnt\n",
    "    cent_y = cent_y//cnt\n",
    "    \n",
    "    # bounding box co-ordinates are pushed in an array\n",
    "    arr = [(min_x,min_y),(min_x,max_y),(max_x,min_y),(max_x,max_y)]\n",
    "    \n",
    "    return cent_x, cent_y, arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_params = dict(maxCorners = 300, qualityLevel = 0.2, minDistance = 2, blockSize = 7)\n",
    "first_frame = cv2.imread(\"../images/1/frames/frame0.jpg\")\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev = cv2.goodFeaturesToTrack(prev_gray, mask = None, **feature_params)\n",
    "\n",
    "# flags used for counting\n",
    "in_below_100 = 0\n",
    "in_above_100 = 0\n",
    "out_above_170 = 0\n",
    "out_below_170 = 0\n",
    "# variables used for counting\n",
    "in_person = 0\n",
    "out_person = 0\n",
    "\n",
    "for index in range(1,125):\n",
    "    frame = cv2.imread(\"../images/1/frames/frame\"+ str(index)+\".jpg\")\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev = cv2.goodFeaturesToTrack(prev_gray, mask = None, **feature_params)\n",
    "\n",
    "    # motion estimation\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 1, 5, 2, 5, 1.1, None)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    # considering only vertical motion\n",
    "    vertical = mag.copy()\n",
    "    for i in range(mag.shape[0]):\n",
    "        for j in range(mag.shape[1]):\n",
    "            vertical[i][j] = mag[i][j] * abs(np.sin(ang[i][j]))\n",
    "\n",
    "    # calculating varying T\n",
    "    ind = 0\n",
    "    temp_array = [0]*(vertical.shape[0]*vertical.shape[1])\n",
    "    for i in range(vertical.shape[0]):\n",
    "        for j in range(vertical.shape[1]):\n",
    "            temp_array[ind] = vertical[i][j]\n",
    "            ind += 1\n",
    "    temp_array = np.array(temp_array)\n",
    "    temp_array = np.sort(temp_array)[::-1]\n",
    "    # top 5%\n",
    "    percent = (2*mag.shape[0]*mag.shape[1])/100\n",
    "    percent = int(percent)\n",
    "    T = temp_array[percent-1]\n",
    "    if T < 2:\n",
    "        T = 100\n",
    "\n",
    "    # Calculating feature value M\n",
    "    dy, dx = np.gradient(gray)\n",
    "    Ixx = dx**2\n",
    "    Iyy = dy**2\n",
    "    Ixy = dx*dy\n",
    "    R_score = np.array(gray.copy(),dtype=np.float64)\n",
    "    for i in range(gray.shape[0]):\n",
    "        for j in range(gray.shape[1]):\n",
    "            sum_Ix = 0\n",
    "            sum_Iy = 0\n",
    "            sum_Ixy = 0\n",
    "            for k in range(-2,3):\n",
    "                for l in range(-2,3):\n",
    "                    if i+k >= 0 and j+l >= 0 and i+k < gray.shape[0] and j+l < gray.shape[1]:\n",
    "                        sum_Ix += Ixx[i+k][j+l]\n",
    "                        sum_Iy += Iyy[i+k][j+l]\n",
    "                        sum_Ixy += Ixy[i+k][j+l]\n",
    "                    else:\n",
    "                        sum_Ix += 0\n",
    "                        sum_Iy += 0\n",
    "                        sum_Ixy += 0\n",
    "            det = sum_Ix*sum_Iy - sum_Ixy*sum_Ixy\n",
    "            trace = sum_Ixy + sum_Ixy\n",
    "            r = det - 0.05*(trace**2)\n",
    "            R_score[i][j] = r \n",
    "    min_val = np.min(R_score)\n",
    "    R_score += (-1)*min_val\n",
    "    max_val = np.max(R_score)\n",
    "    R_score = (R_score/max_val)*255\n",
    "    R_score = R_score.astype(int)\n",
    "    \n",
    "    # choosing top_features\n",
    "    listOfFeatures = []\n",
    "    listTemp = []\n",
    "    for x in range(frame.shape[0]):\n",
    "        for y in range(frame.shape[1]):\n",
    "            listTemp.append([R_score[x][y], x, y])\n",
    "    listTemp.sort()\n",
    "    listTemp.reverse()\n",
    "    for x in range(len(listTemp)):\n",
    "        listOfFeatures.append(listTemp[x])\n",
    "    \n",
    "    # region growing\n",
    "    region = np.zeros((frame.shape[0], frame.shape[1]), dtype=int)\n",
    "    vis = [[False for x in range(frame.shape[1])] for y in range(frame.shape[0])]\n",
    "    for point in listOfFeatures:\n",
    "        area = bfs(point[1], point[2], vis, vertical, T, region)\n",
    "\n",
    "    # component labelling\n",
    "    img_gray = region.copy()\n",
    "    area,re = count_obj(img_gray,255)\n",
    "    thresh1 = 50\n",
    "    ids=[]\n",
    "    for i in area:\n",
    "        if i[0] > thresh1:\n",
    "            ids.append(i[1]+1)\n",
    "    imgc = color_it(re,ids)\n",
    "    imgc[imgc>0] = 255\n",
    "    thresh2 = 3000\n",
    "    img_d=cv2.dilate(imgc,cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7)),iterations=5)\n",
    "    area,re=count_obj(img_d,255)\n",
    "    ids=[]\n",
    "    for i in area:\n",
    "        if i[0] > thresh2:\n",
    "            ids.append(i[1]+1)\n",
    "    imgc = color_it(re,ids)\n",
    "    imgc[imgc>0] = 255\n",
    "    thresh3 = 5000\n",
    "    img_d=cv2.dilate(imgc,cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(9,9)),iterations=3)\n",
    "    area,re=count_obj(img_d,255)\n",
    "    ids=[]\n",
    "    for i in area:\n",
    "        if i[0] > thresh3:\n",
    "            ids.append(i[1]+1)\n",
    "    imgc = color_it(re,ids)\n",
    "    imgc[imgc>0] = 255\n",
    "\n",
    "    # calculating centroid\n",
    "    centroid = []\n",
    "    vis = np.zeros(imgc.shape)\n",
    "    h, w= imgc.shape\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if imgc[i,j] == 255 and vis[i,j] == 0:\n",
    "                # the cent_x and cent_y has x,y coordinate of centroid and the array arr has the bounding box coordinate                \n",
    "                cent_x, cent_y, arr = centroid_bfs(imgc,i,j,1,vis)\n",
    "                centroid.append((cent_x,cent_y,arr))\n",
    "    \n",
    "    # counting people\n",
    "    if len(centroid) == 0:\n",
    "        if out_below_170 == 1:\n",
    "            out_person += 1\n",
    "            out_below_170 = 0\n",
    "        if in_above_100 == 1:\n",
    "            in_above_100 = 0\n",
    "            in_person += 1\n",
    "    for j in range(len(centroid)):\n",
    "        x = centroid[j][0]\n",
    "        y = centroid[j][1]\n",
    "        if x < 100 and y < 210:\n",
    "            if out_below_170 == 0:\n",
    "                in_below_100 = 1\n",
    "        elif x > 100 and x < 170 and y < 210:\n",
    "            if in_below_100 == 1:\n",
    "                in_below_100 = 0\n",
    "                in_above_100 = 1\n",
    "            else:\n",
    "                if out_above_170 == 1:\n",
    "                    out_above_170 = 0\n",
    "                    out_below_170 = 1\n",
    "        elif x > 170 and y < 210:\n",
    "            if in_above_100 == 0:\n",
    "                out_above_170 = 1\n",
    "    print(index,\"  in-person count-  \" ,in_person, \"out-person count-  \" ,out_person)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

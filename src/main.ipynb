{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, collections\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "import sys, os\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# People Counting System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change the video number to see the results on any video present in images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes position(i,j), visited matrix, motion vector matrix and threshold on vector magnitude\n",
    "def bfs(i, j, vis, mag, t, region):\n",
    "    util = [-1, 0, 1]\n",
    "    if mag[i][j] < t or vis[i][j] == True:\n",
    "        return 0\n",
    "    q = collections.deque()\n",
    "    area = 0\n",
    "    vis[i][j] = True\n",
    "    q.append([i,j])\n",
    "    while len(q) > 0:\n",
    "        curX, curY = q.popleft()\n",
    "        region[curX][curY] = 255\n",
    "        area += 1\n",
    "        for a in range(3):\n",
    "            for b in range(3):\n",
    "                x = curX + util[a]\n",
    "                y = curY + util[b]\n",
    "                if x >= 0 and y >= 0 and x < mag.shape[0] and y < mag.shape[1] and vis[x][y] != True:\n",
    "                    vis[x][y] = True  \n",
    "                    if mag[x][y] >= t:\n",
    "                        q.append([x, y])\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to color different segmented objects\n",
    "def color_it(img1,c):\n",
    "    img=np.zeros((img1.shape[0],img1.shape[1]))\n",
    "    for i in range(img1.shape[0]):\n",
    "        for j in range(img1.shape[1]):\n",
    "            if img1[i][j] in c:\n",
    "                img[i][j]=255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to count the area of components\n",
    "def dfs(i,j,img,re,vis,c):\n",
    "    if(i<0 or i>=img.shape[0] or j<0 or j>=img.shape[1] or vis[i][j]==1 or img[i][j]==0):\n",
    "        return 0\n",
    "    else:\n",
    "        vis[i][j] = 1\n",
    "        re[i][j] = c\n",
    "        val = 1\n",
    "        if img[i][j] != 0:\n",
    "            val += dfs(i+1,j,img,re,vis,c)\n",
    "            val += dfs(i-1,j,img,re,vis,c)\n",
    "            val += dfs(i,j+1,img,re,vis,c)\n",
    "            val += dfs(i,j-1,img,re,vis,c)\n",
    "            val += dfs(i+1,j+1,img,re,vis,c)\n",
    "            val += dfs(i-1,j-1,img,re,vis,c)\n",
    "            val += dfs(i-1,j+1,img,re,vis,c)\n",
    "            val += dfs(i+1,j-1,img,re,vis,c)\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving object class for each moving object identified\n",
    "# Stores flags to check the position of the object and the centroid\n",
    "class movObj():\n",
    "    def __init__(self, x, y):\n",
    "        self.cx = x\n",
    "        self.cy = y\n",
    "        self.lin1 = False\n",
    "        self.lin2 = False\n",
    "        self.lout1 = False\n",
    "        self.lout2 = False\n",
    "        self.lastUpdate = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the area\n",
    "def count_obj(img,co=255):\n",
    "    count = 1\n",
    "    area = []\n",
    "    re = np.zeros((img.shape[0],img.shape[1]))\n",
    "    visit = np.zeros((img.shape[0],img.shape[1]))\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if visit[i][j]==0 and img[i][j]==co:\n",
    "                temp=[]\n",
    "                temp.append(dfs(i,j,img,re,visit,count))\n",
    "                temp.append(count-1)\n",
    "                area.append(temp)\n",
    "                count += 1\n",
    "    return area,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating centroid of image \n",
    "def centroid_bfs(img,r,c,col,vis):\n",
    "    h,w = img.shape\n",
    "    q = Queue()\n",
    "    q.put((r,c))\n",
    "    vis[r,c] = 1\n",
    "    cent_x = 0\n",
    "    cent_y = 0\n",
    "    cnt = 0\n",
    "    min_x = h+1\n",
    "    min_y = w+1\n",
    "    max_x = 0\n",
    "    max_y = 0\n",
    "    while not q.empty():\n",
    "        r, c = q.get()\n",
    "        min_x = min(min_x,r)\n",
    "        min_y = min(min_y,c)\n",
    "        max_x = max(max_x,r)\n",
    "        max_y = max(max_y,c)\n",
    "        cnt += 1\n",
    "        cent_x += r\n",
    "        cent_y += c\n",
    "        if r-1>=0 and vis[r-1,c] == 0 and img[r-1,c]!=0:\n",
    "            vis[r-1,c] = col\n",
    "            q.put((r-1,c))\n",
    "        if r+1<h and vis[r+1,c] == 0 and img[r+1,c]!=0:\n",
    "            vis[r+1,c] = 1\n",
    "            q.put((r+1,c))\n",
    "        if c-1>=0 and vis[r,c-1] == 0 and img[r,c-1]!=0:\n",
    "            vis[r,c-1] = 1\n",
    "            q.put((r,c-1))\n",
    "        if c+1<w and vis[r,c+1] == 0 and img[r,c+1]!=0:\n",
    "            vis[r,c+1] = 1\n",
    "            q.put((r,c+1))\n",
    "            \n",
    "    cent_x = cent_x//cnt\n",
    "    cent_y = cent_y//cnt\n",
    "    \n",
    "    # bounding box co-ordinates are pushed in an array\n",
    "    arr = [(min_x,min_y),(min_x,max_y),(max_x,min_y),(max_x,max_y)]\n",
    "    \n",
    "    return cent_x, cent_y, arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of persons identified by algorithm\n",
    "listOfObjects = []\n",
    "\n",
    "# variables used for counting\n",
    "in_person = 0\n",
    "out_person = 0\n",
    "\n",
    "# video obj for converting video to frames after 0.1 seconds\n",
    "vidObj = cv2.VideoCapture(\"../input_videos/video\" + str(video_number) + \".avi\")\n",
    "count = 0\n",
    "success = 1\n",
    "sec = 0\n",
    "\n",
    "# Baselines that act as thresholds while counting people\n",
    "someLineOne = 90\n",
    "someLineTwo = 150\n",
    "\n",
    "if not os.path.exists('../output_results'):\n",
    "    os.makedirs('../output_results')\n",
    "\n",
    "if os.path.exists('../output_results/result' + str(video_number) + \".txt\"):\n",
    "    os.remove('../output_results/result' + str(video_number) + \".txt\")\n",
    "\n",
    "while success:\n",
    "    vidObj.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    success, image = vidObj.read()\n",
    "    # if successfully got the frame\n",
    "    if success == 1:\n",
    "        if count == 0:\n",
    "            first_frame = image \n",
    "            prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            frame = image\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # motion estimation\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 1, 5, 2, 5, 1.1, None)\n",
    "            mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "            prev_gray = gray.copy()\n",
    "\n",
    "            # considering only vertical motion \n",
    "            vertical = mag.copy()\n",
    "            for i in range(mag.shape[0]):\n",
    "                for j in range(mag.shape[1]):\n",
    "                    vertical[i][j] = mag[i][j] * abs(np.sin(ang[i][j]))\n",
    "\n",
    "            # calculating varying T (threshold for motion to be considered)\n",
    "            ind = 0\n",
    "            temp_array = [0]*(vertical.shape[0]*vertical.shape[1])\n",
    "            for i in range(vertical.shape[0]):\n",
    "                for j in range(vertical.shape[1]):\n",
    "                    temp_array[ind] = vertical[i][j]\n",
    "                    ind += 1\n",
    "            temp_array = np.array(temp_array)\n",
    "            temp_array = np.sort(temp_array)[::-1]\n",
    "\n",
    "            # top 5% motion values \n",
    "            percent = (5*mag.shape[0]*mag.shape[1])/100\n",
    "            percent = int(percent)\n",
    "            T = temp_array[percent-1]\n",
    "            # if T is less than 2 we assumed that there is no considerate motion in that frame and we can neglect that frame\n",
    "            if T < 2:\n",
    "                tempList = []\n",
    "                # remove objects that seem to have moved out of the frame\n",
    "                for obj in listOfObjects:\n",
    "                    if obj.lastUpdate + 2  >= count:\n",
    "                        tempList.append(obj)\n",
    "                listOfObjects = tempList.copy()\n",
    "                with open(\"../output_results/result\" + str(video_number) + \".txt\", 'a') as file:\n",
    "                    file.write(\"Time = \" + str(round(count*0.1, 1)) + \"  in-person count - \" + str(in_person) + \"    out-person count - \" + str(out_person))\n",
    "                    file.write('\\n')\n",
    "                count += 1\n",
    "                sec += 0.1\n",
    "                continue\n",
    "\n",
    "            # Calculating feature value M (differential matrix)\n",
    "            dy, dx = np.gradient(gray)\n",
    "            Ixx = dx**2\n",
    "            Iyy = dy**2\n",
    "            Ixy = dx*dy\n",
    "            # R_score is the corner response value considering neighbourhood of 3x3\n",
    "            R_score = np.array(gray.copy(),dtype=np.float64)\n",
    "            for i in range(gray.shape[0]):\n",
    "                for j in range(gray.shape[1]):\n",
    "                    sum_Ix = 0\n",
    "                    sum_Iy = 0\n",
    "                    sum_Ixy = 0\n",
    "                    for k in range(-2,3):\n",
    "                        for l in range(-2,3):\n",
    "                            if i+k >= 0 and j+l >= 0 and i+k < gray.shape[0] and j+l < gray.shape[1]:\n",
    "                                sum_Ix += Ixx[i+k][j+l]\n",
    "                                sum_Iy += Iyy[i+k][j+l]\n",
    "                                sum_Ixy += Ixy[i+k][j+l]\n",
    "                            else:\n",
    "                                sum_Ix += 0\n",
    "                                sum_Iy += 0\n",
    "                                sum_Ixy += 0\n",
    "                    # determinant of Matrix M\n",
    "                    det = sum_Ix*sum_Iy - sum_Ixy*sum_Ixy\n",
    "                    # trace of matrix M\n",
    "                    trace = sum_Ixy + sum_Ixy\n",
    "                    r = det - 0.05*(trace**2)\n",
    "                    R_score[i][j] = r \n",
    "            # converting R_score to 0-255\n",
    "            min_val = np.min(R_score)\n",
    "            R_score += (-1)*min_val\n",
    "            max_val = np.max(R_score)\n",
    "            R_score = (R_score/max_val)*255\n",
    "            R_score = R_score.astype(int)\n",
    "            \n",
    "            # choosing top_features needed to be considered\n",
    "            listOfFeatures = []\n",
    "            listTemp = []\n",
    "            for x in range(frame.shape[0]):\n",
    "                for y in range(frame.shape[1]):\n",
    "                    listTemp.append([R_score[x][y], x, y])\n",
    "            listTemp.sort()\n",
    "            listTemp.reverse()\n",
    "            # considering top total pixel/10 features for feature selection\n",
    "            K = len(listTemp)//10\n",
    "            for x in range(K):\n",
    "                listOfFeatures.append(listTemp[x])\n",
    "            \n",
    "            # region growing\n",
    "            region = np.zeros((frame.shape[0], frame.shape[1]), dtype=int)\n",
    "            vis = [[False for x in range(frame.shape[1])] for y in range(frame.shape[0])]\n",
    "            for point in listOfFeatures:\n",
    "                if vis[point[1]][point[2]] == False:\n",
    "                    area = bfs(point[1], point[2], vis, vertical, T, region)\n",
    "\n",
    "            # component labelling\n",
    "            img_gray = region.copy()\n",
    "\n",
    "            # removing small dots using thresholding \n",
    "            area,re = count_obj(img_gray,255)\n",
    "            thresh1 = 50\n",
    "            ids=[]\n",
    "            for i in area:\n",
    "                if i[0] > thresh1:\n",
    "                    ids.append(i[1]+1)\n",
    "            imgc = color_it(re,ids)\n",
    "            imgc[imgc>0] = 255\n",
    "            thresh2 = 5000\n",
    "\n",
    "            # dilating using rectangular structuring element of 7x7 five times. \n",
    "            img_d=cv2.dilate(imgc,cv2.getStructuringElement(cv2.MORPH_RECT,(7,7)),iterations=5)\n",
    "\n",
    "            # removing components that are not big enough to consider for counting\n",
    "            area,re=count_obj(img_d,255)\n",
    "            ids=[]\n",
    "            for i in area:\n",
    "                if i[0] > thresh2:\n",
    "                    ids.append(i[1]+1)\n",
    "            imgc = color_it(re,ids)\n",
    "            imgc[imgc>0] = 255\n",
    "            thresh3 = 5000\n",
    "            img_d=cv2.dilate(imgc,cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(9,9)),iterations=2)\n",
    "            img_d=cv2.erode(img_d,cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(9,9)),iterations=3)\n",
    "            \n",
    "            # calculating centroid\n",
    "            imgc = img_d.copy()\n",
    "            centroid = []\n",
    "            vis = np.zeros(imgc.shape)\n",
    "            h, w= imgc.shape\n",
    "            for i in range(h):\n",
    "                for j in range(w):\n",
    "                    if imgc[i,j] == 255 and vis[i,j] == 0:\n",
    "                        # the cent_x and cent_y has x,y coordinate of centroid and the array arr has\n",
    "                        # the bounding box coordinate                \n",
    "                        cent_x, cent_y, arr = centroid_bfs(imgc,i,j,1,vis)\n",
    "                        centroid.append((cent_x,cent_y,arr))\n",
    "            \n",
    "            \n",
    "            # counting algorithm based on bounding boxes and centroids to link the currently identified objects\n",
    "            # with the ones identified in the previous frames\n",
    "            for j in range(len(centroid)):\n",
    "                once = False\n",
    "\n",
    "                # x1, x2, y1, y2 form the bounding box\n",
    "                x1, y1 = centroid[j][2][0]\n",
    "                x1 -= 15\n",
    "                y1 -= 15\n",
    "                x2, y2 = centroid[j][2][3]\n",
    "                x2 += 15\n",
    "                y2 += 15 \n",
    "                for obj in listOfObjects:\n",
    "                    # checking if previously identified objects lie within above bounding box\n",
    "                    if obj.cx > x1 and obj.cx < x2 and obj.cy > y1 and obj.cy < y2 and once != True:\n",
    "                        once = True\n",
    "                        prevX = obj.cx\n",
    "                        prevY = obj.cy\n",
    "\n",
    "                        # update centroid of the object\n",
    "                        obj.cx = centroid[j][0]\n",
    "                        obj.cy = centroid[j][1]\n",
    "                        obj.lastUpdate = count\n",
    "\n",
    "                        # below set of conditions check whether the object crosses first line or second line\n",
    "                        # alongwith their direction\n",
    "                        if obj.lin1 == True and obj.cx >= someLineTwo and obj.lin2 == False:\n",
    "                            in_person += 1\n",
    "                            obj.lin2 = True\n",
    "                        elif obj.lout2 == True and obj.cx <= someLineOne and obj.lout1 == False:\n",
    "                            out_person += 1\n",
    "                            obj.lout1 = True\n",
    "                        elif obj.lin1 == False and obj.cx >= someLineOne and prevX <= someLineOne and obj.lin2 == False:\n",
    "                            obj.lin1 = True\n",
    "                        elif obj.lout2 == False and prevX >= someLineTwo and obj.cx <= someLineTwo and obj.lout1 == False:\n",
    "                            obj.lout2 = True\n",
    "                        break\n",
    "                if once == False:\n",
    "                    # if the identified object is identified for the first time, then create a new object of movObj class\n",
    "                    obj = movObj(centroid[j][0], centroid[j][1])\n",
    "                    listOfObjects.append(obj)\n",
    "                    obj.lastUpdate = count\n",
    "            \n",
    "            tempList = []\n",
    "            # remove objects that seem to have moved out of the frame\n",
    "            for obj in listOfObjects:\n",
    "                if obj.lastUpdate + 2  >= count:\n",
    "                    tempList.append(obj)\n",
    "            listOfObjects = tempList.copy()\n",
    "\n",
    "            # printing the final count for the current frame\n",
    "            with open(\"../output_results/result\" + str(video_number) + \".txt\", 'a') as file:\n",
    "                file.write(\"Time = \" + str(round(count*0.1, 1)) + \"  in-person count - \" + str(in_person) + \"    out-person count - \" + str(out_person))\n",
    "                file.write('\\n')\n",
    "    count += 1\n",
    "    sec += 0.1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
